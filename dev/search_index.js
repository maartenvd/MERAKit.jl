var documenterSearchIndex = {"docs":
[{"location":"#MERA.jl-reference","page":"MERA.jl reference","title":"MERA.jl reference","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"MERA.jl provides Julia implementations of some basic Multiscale Entaglement Renormalization Ansatz algorithms. For usage instructions, see the GitHub page. Below you can find the reference documentation, listing all the types and functions.","category":"page"},{"location":"#MERA-types","page":"MERA.jl reference","title":"MERA types","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"GenericMERA\nTernaryMERA\nBinaryMERA\nModifiedBinaryMERA","category":"page"},{"location":"#MERA.GenericMERA","page":"MERA.jl reference","title":"MERA.GenericMERA","text":"GenericMERA{N, LT <: Layer, OT}\n\nA GenericMERA is a collection of Layers. The type of these layers then determines whether the MERA is binary, ternary, etc.\n\nOn conventions and terminology:\n\nThe physical indices of the MERA are at the \"bottom\", the scale invariant part at the \"top\".\nThe counting of layers starts from the bottom, so the layer with physical indices is layer 1. The last layer is the scale invariant one, that then repeats upwards to infinity.\nEach layer is thought of as a linear map from its top, or input space to its bottom, or output space.\n\nThe type parameters are N:  The number of distinct layers (N-1 transition layers and one scale invariant one). LT: Layer type. OT: Operator type. The type of ascended and descended operators for this MERA. Determined       from LT. Typically a TensorMap with input and output indices matching the causal       cone width.\n\nGenericMERA is immutable, and the layers can not be changed after construction. All functions that modify a GenericMERA return new objects.\n\n\n\n\n\n","category":"type"},{"location":"#MERA.TernaryMERA","page":"MERA.jl reference","title":"MERA.TernaryMERA","text":"TernaryMERA{N}\n\nA ternary MERA is a MERA consisting of TernaryLayers.\n\n\n\n\n\n","category":"type"},{"location":"#MERA.BinaryMERA","page":"MERA.jl reference","title":"MERA.BinaryMERA","text":"BinaryMERA{N}\n\nA binary MERA is a MERA consisting of BinaryLayers.\n\n\n\n\n\n","category":"type"},{"location":"#MERA.ModifiedBinaryMERA","page":"MERA.jl reference","title":"MERA.ModifiedBinaryMERA","text":"ModifiedBinaryMERA{N}\n\nA modified binary MERA is a MERA consisting of ModifiedBinaryLayers.\n\n\n\n\n\n","category":"type"},{"location":"#Layer-types","page":"MERA.jl reference","title":"Layer types","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"Layer\nSimpleLayer\nTernaryLayer\nBinaryLayer\nModifiedBinaryLayer","category":"page"},{"location":"#MERA.Layer","page":"MERA.jl reference","title":"MERA.Layer","text":"Abstract supertype of all layer types, e.g. BinaryLayer and TernaryLayer.\n\n\n\n\n\n","category":"type"},{"location":"#MERA.SimpleLayer","page":"MERA.jl reference","title":"MERA.SimpleLayer","text":"SimpleLayer <: Layer\n\nA SimpleLayer is a MERA layer that consists of a set of isometries and/or unitaries, and nothing else. This allows writing convenient generic versions of many methods, reducing code duplication for the concrete Layer types. Every subtype of SimpleLayer should implement the iteration and indexing interfaces to return the various tensors of the layer in the same order in which the constructor takes them in.\n\n\n\n\n\n","category":"type"},{"location":"#MERA.TernaryLayer","page":"MERA.jl reference","title":"MERA.TernaryLayer","text":"TernaryLayer{ST, ET, Tan} <: SimpleLayer\n\nThe type for layers of a ternary MERA.\n\nEach layer consists of two tensors, a 2-to-2 disentangler, often called u, and a 3-to-1 isometry, often called w.\n\nThe type parameters are ST for space type, e.g. ComplexSpace or SU2Space; ET for element type, e.g. Complex{Float64}; and Tan for whether this layer is a tangent layer or not.  If Tan = false, the layer is question is an actual MERA layer. If Tan = true it consists, instead of the actual tensors, of Stiefel/Grassmann tangent vectors of these tensors.\n\nIndex numbering convention is as follows, where the physical indices are at the bottom: Disentangler:\n\n 3|   4|\n +------+\n |  u   |\n +------+\n 1|   2|\n\nIsometry:\n\n    4|\n +-------+\n |   w   |\n +-------+\n 1| 2| 3|\n\n\n\n\n\n","category":"type"},{"location":"#MERA.BinaryLayer","page":"MERA.jl reference","title":"MERA.BinaryLayer","text":"BinaryLayer{ST, ET, Tan} <: SimpleLayer\n\nThe type for layers of a binary MERA.\n\nEach layer consists of two tensors, a 2-to-2 disentangler, often called u, and a 2-to-1 isometry, often called w.\n\nThe type parameters are ST for space type, e.g. ComplexSpace or SU2Space; ET for element type, e.g. Complex{Float64}; and Tan for whether this layer is a tangent layer or not.  If Tan = false, the layer is question is an actual MERA layer. If Tan = true it consists, instead of the actual tensors, of Stiefel/Grassmann tangent vectors of these tensors.\n\nIndex numbering convention is as follows, where the physical indices are at the bottom: Disentangler:\n\n 3|   4|\n +------+\n |  u   |\n +------+\n 1|   2|\n\nIsometry:\n\n   3|\n +------+\n |  w   |\n +------+\n 1|   2|\n\n\n\n\n\n","category":"type"},{"location":"#MERA.ModifiedBinaryLayer","page":"MERA.jl reference","title":"MERA.ModifiedBinaryLayer","text":"ModifiedBinaryLayer{ST, ET, Tan} <: SimpleLayer\n\nThe type for layers of a modified binary MERA.\n\nEach layer consists of three tensors, a 2-to-2 disentangler, often called u, and two 2-to-1 isometries, often called wl and wr, for left and right. Their relative locations are\n\n|     |\nwl   wr\n| \\ / |\n|  u  |\n| / \\ |\n\nThe type parameters are ST for space type, e.g. ComplexSpace or SU2Space; ET for element type, e.g. Complex{Float64}; and Tan for whether this layer is a tangent layer or not.  If Tan = false, the layer is question is an actual MERA layer. If Tan = true it consists, instead of the actual tensors, of Stiefel/Grassmann tangent vectors of these tensors.\n\nIndex numbering convention is as follows, where the physical indices are at the bottom: Disentangler:\n\n 3|   4|\n +------+\n |  u   |\n +------+\n 1|   2|\n\nIsometries:\n\n   3|\n +------+\n |  w   |\n +------+\n 1|   2|\n\n\n\n\n\n","category":"type"},{"location":"#Utility-functions","page":"MERA.jl reference","title":"Utility functions","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"num_translayers\nlayertype\noperatortype\nscalefactor\ncausal_cone_width\nget_layer\noutputspace\ninputspace\ninternalspace\npseudoserialize\ndepseudoserialize\nremove_symmetry\nprojectisometric\nprojectisometric!\nreset_storage","category":"page"},{"location":"#MERA.num_translayers","page":"MERA.jl reference","title":"MERA.num_translayers","text":"num_translayers(m::GenericMERA)\n\nReturn the number of transition layers, i.e. layers below the scale invariant one, in the MERA.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.layertype","page":"MERA.jl reference","title":"MERA.layertype","text":"layertype(m::GenericMERA)\nlayertype(::Type{<:GenericMERA})\n\nReturn the type of the layers of the MERA.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.operatortype","page":"MERA.jl reference","title":"MERA.operatortype","text":"operatortype(m::GenericMERA)\noperatortype(::Type{<: GenericMERA})\n\nReturn the type of operator associate with this MERA or MERA type. That means the type of operator that fits in the causal cone, and is naturally emerges as one ascends local operators.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.scalefactor","page":"MERA.jl reference","title":"MERA.scalefactor","text":"scalefactor(::Type{<: GenericMERA})\n\nThe ratio by which the number of sites changes when one descends by one layer, e.g. 2 for binary MERA, 3 for ternary.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.causal_cone_width","page":"MERA.jl reference","title":"MERA.causal_cone_width","text":"causal_cone_width(::Type{<: GenericMERA})\n\nReturn the width of the stable causal cone for this MERA type.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.get_layer","page":"MERA.jl reference","title":"MERA.get_layer","text":"get_layer(m::GenericMERA, depth)\n\nReturn the layer at the given depth. 1 is the lowest layer, i.e. the one with physical indices.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.outputspace","page":"MERA.jl reference","title":"MERA.outputspace","text":"outputspace(layer::Layer)\n\nReturn the vector space of the downwards-pointing (towards the physical level) indices of `layer.\n\nSee also: inputspace, internalspace\n\n\n\n\n\n","category":"function"},{"location":"#MERA.inputspace","page":"MERA.jl reference","title":"MERA.inputspace","text":"inputspace(layer::Layer)\n\nReturn the vector space of the upwards-pointing (towards the scale invariance) indices of `layer.\n\nSee also: outputspace, internalspace\n\n\n\n\n\n","category":"function"},{"location":"#MERA.internalspace","page":"MERA.jl reference","title":"MERA.internalspace","text":"internalspace(layer::Layer)\n\nReturn the internal vector space of `layer.\n\nSee also: outputspace,  inputspace\n\n\n\n\n\n","category":"function"},{"location":"#MERA.pseudoserialize","page":"MERA.jl reference","title":"MERA.pseudoserialize","text":"pseudoserialize(x)\n\nReturn a tuple of objects that can be used to reconstruct x, and that are all of Julia base types.\n\nThe name refers to how this isn't quite serialization, since it doesn't break objects down to bit strings, but kinda serves the same purpose: pseudoserialised objects can easily be written and read from e.g. disk, without having to worry about quirks of the type system (like with JLD).\n\nSee also: depseudoserialize\n\n\n\n\n\n","category":"function"},{"location":"#MERA.depseudoserialize","page":"MERA.jl reference","title":"MERA.depseudoserialize","text":"depseudoserialize(::Type{T}, args) where T <: GenericMERA\n\nReconstruct an object given the output of pseudoserialize: x -> depseudoserialize(pseudoserialize(x)...) should be an effective noop.\n\nSee also: pseudoserialize\n\n\n\n\n\n","category":"function"},{"location":"#MERA.remove_symmetry","page":"MERA.jl reference","title":"MERA.remove_symmetry","text":"remove_symmetry(V)\n\nStrip a vector space of its symmetry structure, i.e. return the corresponding ℂ^n or ℝ^n.\n\n\n\n\n\nremove_symmetry(t::AbstractTensorMap)\n\nStrip an AbstractTensorMap of its internal symmetries, and return the corresponding TensorMap that operators on ComplexSpace or CartesianSpace.\n\n\n\n\n\nremove_symmetry(m::GenericMERA)\n\nGiven a MERA which may possibly be built of symmetry preserving TensorMaps, return another, equivalent MERA that has the symmetry structure stripped from it, and all tensors are dense.\n\n\n\n\n\n","category":"function"},{"location":"#TensorKitManifolds.projectisometric","page":"MERA.jl reference","title":"TensorKitManifolds.projectisometric","text":"projectisometric(m::GenericMERA)\n\nProject all the tensors of the MERA to respect the isometricity condition.\n\n\n\n\n\n","category":"function"},{"location":"#TensorKitManifolds.projectisometric!","page":"MERA.jl reference","title":"TensorKitManifolds.projectisometric!","text":"projectisometric!(m::GenericMERA)\n\nProject all the tensors of the MERA to respect the isometricity condition, in place.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.reset_storage","page":"MERA.jl reference","title":"MERA.reset_storage","text":"reset_storage(m::GenericMERA)\n\nReset cached operators, so that they will be recomputed when they are needed.\n\n\n\n\n\n","category":"function"},{"location":"#Generating-and-modifying-MERAs","page":"MERA.jl reference","title":"Generating and modifying MERAs","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"replace_layer\nrelease_transitionlayer\nrandom_MERA\nrandomlayer\nexpand_bonddim\nexpand_internal_bonddim","category":"page"},{"location":"#MERA.replace_layer","page":"MERA.jl reference","title":"MERA.replace_layer","text":"replace_layer(c::MERACache, depth)\n\nCreate a new MERACache that has all the stored pieces removed that are invalidated by changing the layer at depth.\n\n\n\n\n\nreplace_layer(m::GenericMERA, layer, depth; check_invar=true)\n\nReplace depth layer of m with layer. If check_invar=true, check that the indices match afterwards.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.release_transitionlayer","page":"MERA.jl reference","title":"MERA.release_transitionlayer","text":"release_transitionlayer(m::GenericMERA)\n\nAdd one more transition layer at the top of the MERA, by taking the lowest of the scale invariant ones and releasing it to vary independently.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.random_MERA","page":"MERA.jl reference","title":"MERA.random_MERA","text":"random_MERA(::Type{T <: GenericMERA}, ET, Vouts, Vints=Vouts; kwargs...)\n\nGenerate a random MERA of type T.\n\nET is the element type of the MERA, e.g. Float64. Vouts are the vector spaces between the various layers. Number of layers will be the length of Vouts. Vouts[1] will be the physical index space, and Vs[end] will be the one at the scale invariant layer. Vints can be a vector/tuple of the same length as Vouts, and include vector spaces for the internal indices of each layer. Alternatively, it can hold any other extra parameters specific to each layer, as it is simply passed on to the function randomlayer. Also passed to randomlayer will be any additional keyword arguments, but these will all be the same for each layer.\n\nSee also: randomlayer\n\n\n\n\n\n","category":"function"},{"location":"#MERA.randomlayer","page":"MERA.jl reference","title":"MERA.randomlayer","text":"randomlayer(::Type{T <: Layer}, T, Vin, Vout, Vint=Vout; random_disentangler=false)\n\nReturn a MERA layer with random tensors.\n\nT is the Layer type, and Vin and Vout are the input and output spaces. Vint is an internal vector space for the layer, connecting the disentanglers to the isometries. If random_disentangler=true, the disentangler is also a random unitary, if false (default), it is the identity or the product of two single-site isometries, depending on if the disentanler is supposed to be unitary or isometric.\n\nEach subtype of Layer should have its own method for this function.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.expand_bonddim","page":"MERA.jl reference","title":"MERA.expand_bonddim","text":"expand_bonddim(m::GenericMERA, depth, newdims; check_invar=true)\n\nExpand the bond dimension of the MERA at the given depth.\n\nThe indices to expand are the input indices of the layer at depth, i.e. depth=1 means the lowest virtual indices. The new bond dimension is given by newdims, which for a non-symmetric MERA is just a number, and for a symmetric MERA is a dictionary of irrep => block dimension. Not all irreps for a bond need to be listed, the ones left out are left untouched.\n\nThe expansion is done by padding tensors with zeros. Note that this breaks isometricity of the individual tensors. This is however of no consequence, since the MERA as a state remains exactly the same. A round of optimization on the MERA will restore isometricity of each tensor, or projectisometric can be called to do so explicitly.\n\nIf check_invar = true the function checks that the bond dimensions of various layers match after the expansion.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.expand_internal_bonddim","page":"MERA.jl reference","title":"MERA.expand_internal_bonddim","text":"expand_internal_bonddim(m::GenericMERA, depth, newdims; check_invar=true)\n\nExpand the bond dimension of the layer-internal indices of the MERA at the given depth.\n\nThe new bond dimension is given by newdims, which for a non-symmetric MERA is just a number, and for a symmetric MERA is a dictionary of {irrep => block dimension}. Not all irreps for a bond need to be listed, the ones left out are left untouched.\n\nThe expansion is done by padding tensors with zeros. Note that this breaks isometricity of the individual tensors. This is however of no consequence, since the MERA as a state remains exactly the same. A round of optimization on the MERA will restore isometricity of each tensor, or projectisometric can be called to do so explicitly.\n\nNote that not all MERAs have an internal bond dimension, and some may have several, so this function will not make sense for all MERA types. Implementation relies on the function expand_internalspace, defined for each Layer type.\n\n\n\n\n\n","category":"function"},{"location":"#Measuring-physical-quantities","page":"MERA.jl reference","title":"Measuring physical quantities","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"expect\nscalingdimensions\ndensitymatrix_entropies","category":"page"},{"location":"#MERA.expect","page":"MERA.jl reference","title":"MERA.expect","text":"expect(op, m::GenericMERA, pars=(;), opscale=1, evalscale=1)\n\nReturn the expecation value of operator op for the MERA m.\n\nThe layer on which op lives is set by opscale, which by default is the physical one. evalscale can be used to set whether the operator is ascended through the network or the density matrix is descended. pars can hold additional options that are further down the line passed on to fixedpoint_densitymatrix.\n\nSee also: fixedpoint_densitymatrix\n\n\n\n\n\n","category":"function"},{"location":"#MERA.scalingdimensions","page":"MERA.jl reference","title":"MERA.scalingdimensions","text":"scalingdimensions(m::GenericMERA, howmany=20)\n\nDiagonalize the scale invariant ascending superoperator to compute the scaling dimensions of the underlying CFT.\n\nThe return value is a dictionary, the keys of which are symmetry sectors for a possible internal symmetry of the MERA (Trivial() if there is no internal symmetry), and values are scaling dimensions in this symmetry sector.\n\nhowmany controls how many of lowest scaling dimensions are computed.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.densitymatrix_entropies","page":"MERA.jl reference","title":"MERA.densitymatrix_entropies","text":"densitymatrix_entropies(m::GenericMERA)\n\nReturn a vector of entropies for the density matrices in the MERA. The first one is for the density matrix at the physical level, the last one is the scale invariant density matrix.\n\n\n\n\n\n","category":"function"},{"location":"#Ascending-operators","page":"MERA.jl reference","title":"Ascending operators","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"ascend\nascended_operator\nscale_invariant_operator_sum","category":"page"},{"location":"#MERA.ascend","page":"MERA.jl reference","title":"MERA.ascend","text":"ascend(op, layer::Layer)\n\nAscend a local operator op from the bottom of layer to the top.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.ascended_operator","page":"MERA.jl reference","title":"MERA.ascended_operator","text":"ascended_operator(m::GenericMERA, op, depth)\n\nReturn the operator op ascended from the physical level to depth.\n\nThis function utilises the cache, to avoid recomputation.\n\nSee also: scale_invariant_operator_sum\n\n\n\n\n\n","category":"function"},{"location":"#MERA.scale_invariant_operator_sum","page":"MERA.jl reference","title":"MERA.scale_invariant_operator_sum","text":"scale_invariant_operator_sum(m::GenericMERA, op, pars)\n\nReturn the sum of the ascended versions of op in the scale invariant part of the MERA.\n\nTo be more precise, this sum is of course infinite, and what we return is the component of it orthogonal to the dominant eigenoperator of the ascending superoperator (typically the identity). This component converges to a finite result like a geometric series, since all non-dominant eigenvalues of the ascending superoperator are smaller than 1.\n\nTo approximate the converging series, we use an iterative Krylov solver. The options for the solver should be in pars.scaleinvariant_krylovoptions, they will be passed to KrylovKit.linsolve.\n\n\n\n\n\n","category":"function"},{"location":"#Descending-density-matrices","page":"MERA.jl reference","title":"Descending density matrices","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"descend\ndensitymatrix\ndensitymatrices\nfixedpoint_densitymatrix","category":"page"},{"location":"#MERA.descend","page":"MERA.jl reference","title":"MERA.descend","text":"descend(rho, layer::Layer)\n\nDescend a local density matrix rho from the top of layer to the bottom.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.densitymatrix","page":"MERA.jl reference","title":"MERA.densitymatrix","text":"densitymatrix(m::GenericMERA, depth, pars=(;))\n\nReturn the density matrix right below the layer at depth.\n\npars maybe a NamedTuple of options, passed on to the function fixedpoint_densitymatrix.\n\nThis function utilises the cache, to avoid recomputation.\n\nSee also: fixedpoint_densitymatrix, densitymatrices\n\n\n\n\n\n","category":"function"},{"location":"#MERA.densitymatrices","page":"MERA.jl reference","title":"MERA.densitymatrices","text":"densitymatrices(m::GenericMERA, pars=(;))\n\nReturn all the distinct density matrices of the MERA, starting with the one at the physical level, and ending with the scale invariant one.\n\npars maybe a NamedTuple of options, passed on to the function fixedpoint_densitymatrix.\n\nSee also: fixedpoint_densitymatrix, densitymatrix\n\n\n\n\n\n","category":"function"},{"location":"#MERA.fixedpoint_densitymatrix","page":"MERA.jl reference","title":"MERA.fixedpoint_densitymatrix","text":"fixedpoint_densitymatrix(m::GenericMERA, pars::NamedTuple=(;))\n\nFind the fixed point density matrix of the scale invariant part of the MERA.\n\nTo find the fixed point, we use an iterative Krylov solver. The options for the solver should be in pars.scaleinvariant_krylovoptions, they will be passed to KrylovKit.eigsolve.\n\n\n\n\n\n","category":"function"},{"location":"#Optimizing-a-MERA","page":"MERA.jl reference","title":"Optimizing a MERA","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"minimize_expectation\nenvironment\ngradient\nretract\ntransport!\ninner\ntensorwise_sum\ntensorwise_scale","category":"page"},{"location":"#MERA.minimize_expectation","page":"MERA.jl reference","title":"MERA.minimize_expectation","text":"minimize_expectation(m::GenericMERA, h, pars=(;);\n                     finalize! = OptimKit._finalize!, vary_disentanglers=true,\n                     kwargs...)\n\nReturn a MERA optimized to minimize the expectation value of operator h, starting with m as the initial guess.\n\npars is a NamedTuple of parameters for the optimisation. They are,\n\nmethod: A Symbol that chooses which optimisation method to use. Options are :lbfgs for L-BFGS (default), :ev for Evenbly-Vidal, :cg for conjugate gradient, and :gd for gradient descent. :lbfgs, :cg, and :gd are together known as the gradient methods.\nmaxiter: Maximum number of iterations to use. 2000 by default.\ngradient_delta: Convergence threshold, as measured by the norm of the gradient. 1e-14 by default.\nprecondition: Whether to apply preconditioning with the physical Hilbert space inner product. true by default. See https://arxiv.org/abs/2007.03638 for more details.\nverbosity: How much output to log. 2 by default.\nisometries_only_iters: An integer for how many iterations should at first be done optimising only the isometries, and leaving the disentangler be. 0 by default.\nscaleinvariant_krylovoptions: A NamedTuple of keyword arguments passed to KrylovKit.linsolve and KrylovKit.eigsolve, when solving for the fixed-point density matrix and the scale invariant operator sum. The default is (tol = 1e-13, verbosity = 0, maxiter = 20).\nretraction: Which retraction method to use. Options are :exp for geodesics (default), and :cayley for Cayley transforms. Only affects gradient methods.\ntransport: Which vector transport method to use. Currently each retractionmethod only comes with a single compatible transport, so one should always usetransportto be the same asretraction`. This may change. Only affects gradient methods.\nmetric: Which metric to use for Stiefel manifold. Options are :euclidean (default) and :canonical. Only affects gradient methods.\nls_epsilon: The ϵ parameter for the Hager-Zhang line search. 1e-6 be default. Only affects gradient methods.\nlbfgs_m: The rank of the approximation of the inverse Hessian in L-BFGS. 8 by default. Only affects the :lbfgs method.\ncg_flavor: The \"flavor\" of conjguate gradient to use. :HagerZhang by default. Only affects the :cg: method.\nev_layer_iters: How many times a single layer is optimised before moving to the next layer in the Evenbly-Vidal algorithm. 1 by default. Only affects the :ev method.\n\nIf any of these are specified in pars, the specified values override the defaults.\n\nfinalize! is a function that will be called at every iteration. It can be used to for instance log the development of some quantity during the optimisation, or modify the MERA in some custom (although undefined behavior may follow depending on how the state is changed). Its signature is finalize!(m, f, g, counter) where m is the current MERA, f is its expectation value for h, g is the gradient MERA at m, and counter is the current iteration number. It should return the possibly modified m, f, and g. If method = :ev, then it should also be able to handle the case g = nothing, since the Evenbly-Vidal algorithm does not use gradients.\n\nvary_disentanglers gives the option of running the optimisation but only for the isometries, leaving the disentanglers as they are.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.environment","page":"MERA.jl reference","title":"MERA.environment","text":"environment(layer::Layer, op, rho; vary_disentanglers=true)\n\nCompute the environments with respect to op of all the tensors in the layer, and return them as a Layer. rho is the local density matrix at the top indices of this layer.\n\nIf vary_disentanglers=false, only compute the environments for the isometries, and set the environments for the disentanglers to zero.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.gradient","page":"MERA.jl reference","title":"MERA.gradient","text":"gradient(h, m::GenericMERA, pars::NamedTuple; vary_disentanglers=true)\n\nCompute the gradient of the expectation value of h at the point m.\n\npars should have pars.metric that specifies whether to use the :euclidean or :canonical metric for the Stiefel manifold, and pars.scaleinvariant_krylovoptions that is passed on to environment.\n\nvary_disentanglers allows computing the gradients only for the isometries, and setting the gradients for the disentanglers to zero.\n\nThe return value is a \"tangent MERA\": An object of a similar type as m, but instead of regular layers with tensors that have isometricity constraints, instead each layer holds the corresponding gradients for each tensor.\n\n\n\n\n\n","category":"function"},{"location":"#TensorKitManifolds.retract","page":"MERA.jl reference","title":"TensorKitManifolds.retract","text":"retract(m::GenericMERA, mtan::GenericMERA, alpha::Real; kwargs...)\n\nGiven a \"tangent MERA\" mtan, at base point m, retract in the direction of mtan by distance alpha. This is done tensor-by-tensor, i.e. each tensor is retracted along its respective Stiefel/Grassmann tangent.\n\nThe additional keyword argument are passed on to the respective TensorKitManifolds function.\n\nSee TensorKitManifolds.retract for more details.\n\nSee also: transport!\n\n\n\n\n\n","category":"function"},{"location":"#TensorKitManifolds.transport!","page":"MERA.jl reference","title":"TensorKitManifolds.transport!","text":"transport!(mvec::GenericMERA, m::GenericMERA, mtan::GenericMERA, alpha::Real,\n           mend::GenericMERA; kwargs...)\n\nGiven a \"tangent MERAs\" mtan and mvec, at base point m, transport mvec in the direction of mtan by distance alpha. This is done tensor-by-tensor, i.e. each tensor is transported along its respective Stiefel/Grassmann tangent.\n\nmend is the endpoint on the manifold, i.e. the result of retracting by alpha in the direction of mtan. The additional keyword argument are passed on to the respective TensorKitManifolds function.\n\nSee TensorKitManifolds.transport! for more details.\n\nSee also: retract\n\n\n\n\n\n","category":"function"},{"location":"#TensorKitManifolds.inner","page":"MERA.jl reference","title":"TensorKitManifolds.inner","text":"inner(m::GenericMERA, m1::GenericMERA, m2::GenericMERA; metric=:euclidean)\n\nGiven two tangent MERAs m1 and m2, both at base point m, compute their inner product. This means the sum of the inner products of the individual tensors.\n\nSee TensorKitManifolds.inner for more details.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.tensorwise_sum","page":"MERA.jl reference","title":"MERA.tensorwise_sum","text":"tensorwise_sum(m1::T, m2::T) where T <: GenericMERA\n\nReturn a MERA for which each tensor is the sum of the corresponding tensors of m1 and m2.\n\n\n\n\n\n","category":"function"},{"location":"#MERA.tensorwise_scale","page":"MERA.jl reference","title":"MERA.tensorwise_scale","text":"tensorwise_scale(m::GenericMERA, alpha::Number)\n\nScale all the tensors of m by alpha.\n\n\n\n\n\n","category":"function"},{"location":"#Index","page":"MERA.jl reference","title":"Index","text":"","category":"section"},{"location":"","page":"MERA.jl reference","title":"MERA.jl reference","text":"","category":"page"}]
}
